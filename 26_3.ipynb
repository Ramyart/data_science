Audiobooks Business Case Project:
import numpy as np

import tensorflow as tf 

from sklearn import preprocessing
raw_csv_data = np.loadtxt('33_Audiobooks_data_Without_Headers.csv', delimiter = ',')
Challenge 1:


unscaled_inputs_all = raw_csv_data[:,1:-1]

targets_all = raw_csv_data[:,-1]
Note:

the statement sequence [start : stop] returns the items
sequence[start] and sequence [stop-1], and all the items between them.

Balance the dataset
num_one_targets = int(np.sum(targets_all))
print(num_one_targets)
2237
Recall that:

YiAo9.png

zero_targets_counter = 0

indices_to_remove = []



for i in range(targets_all.shape[0]):
    if targets_all[i] == 0:
        zero_targets_counter += 1
        if zero_targets_counter > num_one_targets:
            indices_to_remove.append(i)
Pay attention to np.delete

000349.png

unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis=0)

targets_equal_priors = np.delete(targets_all, indices_to_remove, axis=0)
Standardize the inputs
scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)
Challenge 2:

At the end, you should try to run the algorithm WITHOUT this line of code (In the above cell). The result will be interesting. Give it a shot.
Shuffle the data
Note:

When the data was collected, it was actually arranged by date.
Shuffle the indices of the data, so the data is not arranged in any way when we feed it.
Since we will be batching, we want the data to be as randomly spread out as possible.
Take care of np.arange

000350.png

For integer arguments the function is equivalent to the Python built-in range function, but returns an ndarray rather than a list.
Example: np.arange(3)
Output: array([0, 1, 2])
shuffled_indices = np.arange(scaled_inputs.shape[0])

np.random.shuffle(shuffled_indices)

shuffled_inputs = scaled_inputs[shuffled_indices]

shuffled_targets = targets_equal_priors[shuffled_indices]
Split the dataset into train, validation, and test
samples_count = shuffled_inputs.shape[0]
samples_count
4474
assuming we want 80-10-10 distribution of training, validation, and test.
train_samples_count = int(0.8 * samples_count)

validation_samples_count = int(0.1 * samples_count)

test_samples_count = samples_count - train_samples_count - validation_samples_count

print(train_samples_count, validation_samples_count, test_samples_count)
3579 447 448
000351.png

train_inputs = shuffled_inputs[:train_samples_count]

train_targets = shuffled_targets[:train_samples_count]
validation_inputs = shuffled_inputs[train_samples_count : train_samples_count + validation_samples_count]

validation_targets = shuffled_targets[train_samples_count : train_samples_count + validation_samples_count]
test_inputs = shuffled_inputs[train_samples_count + validation_samples_count:]

test_targets = shuffled_targets[train_samples_count + validation_samples_count:]
print(np.sum(train_targets), train_samples_count, np.sum(train_targets) / train_samples_count)

print(np.sum(validation_targets), validation_samples_count, np.sum(validation_targets) / validation_samples_count)
print(np.sum(test_targets), test_samples_count, np.sum(test_targets) / test_samples_count)
1782.0 3579 0.4979044425817267
231.0 447 0.5167785234899329
224.0 448 0.5
Save the three datasets in *.npz
np.savez('Audiobooks_data_train', inputs = train_inputs, targets = train_targets)

np.savez('Audiobooks_data_validation', inputs = validation_inputs, targets = validation_targets)

np.savez('Audiobooks_data_test', inputs = test_inputs, targets = test_targets)
Loading our Data from the npz files
000353.png

npz = np.load('Audiobooks_data_train.npz')

train_inputs = npz['inputs'].astype(float)
train_targets = npz['targets'].astype(int)
Note:

targets must be int because of sparse_categorical_crossentropy (we want to be able to smoothly one-hot encode them)
npz2 = np.load('Audiobooks_data_validation.npz')

validation_inputs, validation_targets = npz2['inputs'].astype(float), npz2['targets'].astype(int)
npz3 = np.load('Audiobooks_data_test.npz')

test_inputs, test_targets = npz3['inputs'].astype(float), npz3['targets'].astype(int)
Our Model

000352.png

input_size = 10

output_size = 2

hidden_layer_size = 50
model = tf.keras.Sequential([
    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),
    
    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), 
    
    tf.keras.layers.Dense(output_size, activation='softmax')
])
000354.png

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
batch_size = 100

max_epochs = 100
fit the model, just note that this time the train, validation and test data are not iterable as in the MNIST case
model.fit(train_inputs, 
          
          train_targets,
          
          batch_size=batch_size, 
          
          epochs=max_epochs, 
          
          validation_data=(validation_inputs, validation_targets), 
          
          verbose = 2)  
Epoch 1/100
36/36 - 0s - loss: 0.6014 - accuracy: 0.6658 - val_loss: 0.5074 - val_accuracy: 0.7450
Epoch 2/100
36/36 - 0s - loss: 0.4652 - accuracy: 0.7664 - val_loss: 0.4247 - val_accuracy: 0.7673
Epoch 3/100
36/36 - 0s - loss: 0.4088 - accuracy: 0.7910 - val_loss: 0.4007 - val_accuracy: 0.7584
Epoch 4/100
36/36 - 0s - loss: 0.3815 - accuracy: 0.8025 - val_loss: 0.3800 - val_accuracy: 0.7987
Epoch 5/100
36/36 - 0s - loss: 0.3695 - accuracy: 0.7988 - val_loss: 0.3611 - val_accuracy: 0.8188
Epoch 6/100
36/36 - 0s - loss: 0.3588 - accuracy: 0.8122 - val_loss: 0.3548 - val_accuracy: 0.7987
Epoch 7/100
36/36 - 0s - loss: 0.3533 - accuracy: 0.8128 - val_loss: 0.3539 - val_accuracy: 0.7919
Epoch 8/100
36/36 - 0s - loss: 0.3477 - accuracy: 0.8159 - val_loss: 0.3436 - val_accuracy: 0.8210
Epoch 9/100
36/36 - 0s - loss: 0.3441 - accuracy: 0.8153 - val_loss: 0.3531 - val_accuracy: 0.8166
Epoch 10/100
36/36 - 0s - loss: 0.3424 - accuracy: 0.8203 - val_loss: 0.3352 - val_accuracy: 0.8300
Epoch 11/100
36/36 - 0s - loss: 0.3400 - accuracy: 0.8198 - val_loss: 0.3430 - val_accuracy: 0.8166
Epoch 12/100
36/36 - 0s - loss: 0.3366 - accuracy: 0.8234 - val_loss: 0.3458 - val_accuracy: 0.8166
Epoch 13/100
36/36 - 0s - loss: 0.3325 - accuracy: 0.8237 - val_loss: 0.3370 - val_accuracy: 0.8076
Epoch 14/100
36/36 - 0s - loss: 0.3326 - accuracy: 0.8259 - val_loss: 0.3271 - val_accuracy: 0.8322
Epoch 15/100
36/36 - 0s - loss: 0.3352 - accuracy: 0.8125 - val_loss: 0.3400 - val_accuracy: 0.8076
Epoch 16/100
36/36 - 0s - loss: 0.3311 - accuracy: 0.8181 - val_loss: 0.3268 - val_accuracy: 0.8188
Epoch 17/100
36/36 - 0s - loss: 0.3274 - accuracy: 0.8220 - val_loss: 0.3407 - val_accuracy: 0.7919
Epoch 18/100
36/36 - 0s - loss: 0.3255 - accuracy: 0.8298 - val_loss: 0.3297 - val_accuracy: 0.8412
Epoch 19/100
36/36 - 0s - loss: 0.3272 - accuracy: 0.8259 - val_loss: 0.3362 - val_accuracy: 0.8098
Epoch 20/100
36/36 - 0s - loss: 0.3252 - accuracy: 0.8262 - val_loss: 0.3270 - val_accuracy: 0.8188
Epoch 21/100
36/36 - 0s - loss: 0.3248 - accuracy: 0.8240 - val_loss: 0.3622 - val_accuracy: 0.7875
Epoch 22/100
36/36 - 0s - loss: 0.3266 - accuracy: 0.8259 - val_loss: 0.3227 - val_accuracy: 0.8412
Epoch 23/100
36/36 - 0s - loss: 0.3198 - accuracy: 0.8324 - val_loss: 0.3208 - val_accuracy: 0.8300
Epoch 24/100
36/36 - 0s - loss: 0.3199 - accuracy: 0.8262 - val_loss: 0.3212 - val_accuracy: 0.8233
Epoch 25/100
36/36 - 0s - loss: 0.3183 - accuracy: 0.8307 - val_loss: 0.3222 - val_accuracy: 0.8322
Epoch 26/100
36/36 - 0s - loss: 0.3177 - accuracy: 0.8335 - val_loss: 0.3293 - val_accuracy: 0.8277
Epoch 27/100
36/36 - 0s - loss: 0.3194 - accuracy: 0.8296 - val_loss: 0.3159 - val_accuracy: 0.8389
Epoch 28/100
36/36 - 0s - loss: 0.3189 - accuracy: 0.8273 - val_loss: 0.3182 - val_accuracy: 0.8412
Epoch 29/100
36/36 - 0s - loss: 0.3194 - accuracy: 0.8248 - val_loss: 0.3151 - val_accuracy: 0.8434
Epoch 30/100
36/36 - 0s - loss: 0.3165 - accuracy: 0.8287 - val_loss: 0.3236 - val_accuracy: 0.8389
Epoch 31/100
36/36 - 0s - loss: 0.3165 - accuracy: 0.8312 - val_loss: 0.3180 - val_accuracy: 0.8255
Epoch 32/100
36/36 - 0s - loss: 0.3177 - accuracy: 0.8326 - val_loss: 0.3115 - val_accuracy: 0.8456
Epoch 33/100
36/36 - 0s - loss: 0.3174 - accuracy: 0.8251 - val_loss: 0.3225 - val_accuracy: 0.8098
Epoch 34/100
36/36 - 0s - loss: 0.3163 - accuracy: 0.8279 - val_loss: 0.3138 - val_accuracy: 0.8479
Epoch 35/100
36/36 - 0s - loss: 0.3134 - accuracy: 0.8321 - val_loss: 0.3152 - val_accuracy: 0.8412
Epoch 36/100
36/36 - 0s - loss: 0.3128 - accuracy: 0.8332 - val_loss: 0.3160 - val_accuracy: 0.8389
Epoch 37/100
36/36 - 0s - loss: 0.3130 - accuracy: 0.8326 - val_loss: 0.3221 - val_accuracy: 0.8255
Epoch 38/100
36/36 - 0s - loss: 0.3130 - accuracy: 0.8340 - val_loss: 0.3172 - val_accuracy: 0.8345
Epoch 39/100
36/36 - 0s - loss: 0.3116 - accuracy: 0.8324 - val_loss: 0.3165 - val_accuracy: 0.8076
Epoch 40/100
36/36 - 0s - loss: 0.3114 - accuracy: 0.8259 - val_loss: 0.3252 - val_accuracy: 0.8322
Epoch 41/100
36/36 - 0s - loss: 0.3120 - accuracy: 0.8329 - val_loss: 0.3178 - val_accuracy: 0.8300
Epoch 42/100
36/36 - 0s - loss: 0.3117 - accuracy: 0.8273 - val_loss: 0.3183 - val_accuracy: 0.8479
Epoch 43/100
36/36 - 0s - loss: 0.3157 - accuracy: 0.8217 - val_loss: 0.3175 - val_accuracy: 0.8255
Epoch 44/100
36/36 - 0s - loss: 0.3115 - accuracy: 0.8329 - val_loss: 0.3077 - val_accuracy: 0.8233
Epoch 45/100
36/36 - 0s - loss: 0.3124 - accuracy: 0.8284 - val_loss: 0.3132 - val_accuracy: 0.8300
Epoch 46/100
36/36 - 0s - loss: 0.3124 - accuracy: 0.8273 - val_loss: 0.3096 - val_accuracy: 0.8345
Epoch 47/100
36/36 - 0s - loss: 0.3110 - accuracy: 0.8338 - val_loss: 0.3147 - val_accuracy: 0.8210
Epoch 48/100
36/36 - 0s - loss: 0.3103 - accuracy: 0.8340 - val_loss: 0.3199 - val_accuracy: 0.8523
Epoch 49/100
36/36 - 0s - loss: 0.3134 - accuracy: 0.8270 - val_loss: 0.3086 - val_accuracy: 0.8412
Epoch 50/100
36/36 - 0s - loss: 0.3117 - accuracy: 0.8335 - val_loss: 0.3104 - val_accuracy: 0.8546
Epoch 51/100
36/36 - 0s - loss: 0.3100 - accuracy: 0.8349 - val_loss: 0.3149 - val_accuracy: 0.8546
Epoch 52/100
36/36 - 0s - loss: 0.3126 - accuracy: 0.8270 - val_loss: 0.3079 - val_accuracy: 0.8367
Epoch 53/100
36/36 - 0s - loss: 0.3112 - accuracy: 0.8284 - val_loss: 0.3144 - val_accuracy: 0.8367
Epoch 54/100
36/36 - 0s - loss: 0.3091 - accuracy: 0.8312 - val_loss: 0.3176 - val_accuracy: 0.8322
Epoch 55/100
36/36 - 0s - loss: 0.3096 - accuracy: 0.8284 - val_loss: 0.3081 - val_accuracy: 0.8412
Epoch 56/100
36/36 - 0s - loss: 0.3079 - accuracy: 0.8310 - val_loss: 0.3113 - val_accuracy: 0.8434
Epoch 57/100
36/36 - 0s - loss: 0.3078 - accuracy: 0.8324 - val_loss: 0.3139 - val_accuracy: 0.8434
Epoch 58/100
36/36 - 0s - loss: 0.3089 - accuracy: 0.8318 - val_loss: 0.3130 - val_accuracy: 0.8233
Epoch 59/100
36/36 - 0s - loss: 0.3093 - accuracy: 0.8254 - val_loss: 0.3086 - val_accuracy: 0.8591
Epoch 60/100
36/36 - 0s - loss: 0.3068 - accuracy: 0.8324 - val_loss: 0.3118 - val_accuracy: 0.8367
Epoch 61/100
36/36 - 0s - loss: 0.3051 - accuracy: 0.8324 - val_loss: 0.3270 - val_accuracy: 0.8322
Epoch 62/100
36/36 - 0s - loss: 0.3068 - accuracy: 0.8346 - val_loss: 0.3095 - val_accuracy: 0.8367
Epoch 63/100
36/36 - 0s - loss: 0.3061 - accuracy: 0.8332 - val_loss: 0.3110 - val_accuracy: 0.8345
Epoch 64/100
36/36 - 0s - loss: 0.3055 - accuracy: 0.8360 - val_loss: 0.3171 - val_accuracy: 0.8367
Epoch 65/100
36/36 - 0s - loss: 0.3073 - accuracy: 0.8332 - val_loss: 0.3157 - val_accuracy: 0.8322
Epoch 66/100
36/36 - 0s - loss: 0.3058 - accuracy: 0.8349 - val_loss: 0.3113 - val_accuracy: 0.8412
Epoch 67/100
36/36 - 0s - loss: 0.3063 - accuracy: 0.8343 - val_loss: 0.3092 - val_accuracy: 0.8434
Epoch 68/100
36/36 - 0s - loss: 0.3101 - accuracy: 0.8318 - val_loss: 0.3075 - val_accuracy: 0.8434
Epoch 69/100
36/36 - 0s - loss: 0.3080 - accuracy: 0.8321 - val_loss: 0.3213 - val_accuracy: 0.8166
Epoch 70/100
36/36 - 0s - loss: 0.3076 - accuracy: 0.8307 - val_loss: 0.3223 - val_accuracy: 0.8300
Epoch 71/100
36/36 - 0s - loss: 0.3108 - accuracy: 0.8287 - val_loss: 0.3072 - val_accuracy: 0.8389
Epoch 72/100
36/36 - 0s - loss: 0.3112 - accuracy: 0.8290 - val_loss: 0.3106 - val_accuracy: 0.8233
Epoch 73/100
36/36 - 0s - loss: 0.3060 - accuracy: 0.8321 - val_loss: 0.3119 - val_accuracy: 0.8389
Epoch 74/100
36/36 - 0s - loss: 0.3061 - accuracy: 0.8329 - val_loss: 0.3149 - val_accuracy: 0.8479
Epoch 75/100
36/36 - 0s - loss: 0.3049 - accuracy: 0.8296 - val_loss: 0.3058 - val_accuracy: 0.8300
Epoch 76/100
36/36 - 0s - loss: 0.3054 - accuracy: 0.8329 - val_loss: 0.3093 - val_accuracy: 0.8345
Epoch 77/100
36/36 - 0s - loss: 0.3062 - accuracy: 0.8310 - val_loss: 0.3111 - val_accuracy: 0.8456
Epoch 78/100
36/36 - 0s - loss: 0.3097 - accuracy: 0.8318 - val_loss: 0.3077 - val_accuracy: 0.8389
Epoch 79/100
36/36 - 0s - loss: 0.3056 - accuracy: 0.8385 - val_loss: 0.3245 - val_accuracy: 0.8345
Epoch 80/100
36/36 - 0s - loss: 0.3056 - accuracy: 0.8354 - val_loss: 0.3188 - val_accuracy: 0.8322
Epoch 81/100
36/36 - 0s - loss: 0.3049 - accuracy: 0.8312 - val_loss: 0.3064 - val_accuracy: 0.8501
Epoch 82/100
36/36 - 0s - loss: 0.3113 - accuracy: 0.8298 - val_loss: 0.3039 - val_accuracy: 0.8523
Epoch 83/100
36/36 - 0s - loss: 0.3055 - accuracy: 0.8385 - val_loss: 0.3139 - val_accuracy: 0.8389
Epoch 84/100
36/36 - 0s - loss: 0.3065 - accuracy: 0.8349 - val_loss: 0.3194 - val_accuracy: 0.8054
Epoch 85/100
36/36 - 0s - loss: 0.3059 - accuracy: 0.8335 - val_loss: 0.3131 - val_accuracy: 0.8456
Epoch 86/100
36/36 - 0s - loss: 0.3061 - accuracy: 0.8262 - val_loss: 0.3086 - val_accuracy: 0.8434
Epoch 87/100
36/36 - 0s - loss: 0.3083 - accuracy: 0.8326 - val_loss: 0.3207 - val_accuracy: 0.8188
Epoch 88/100
36/36 - 0s - loss: 0.3067 - accuracy: 0.8321 - val_loss: 0.3142 - val_accuracy: 0.8300
Epoch 89/100
36/36 - 0s - loss: 0.3018 - accuracy: 0.8357 - val_loss: 0.3063 - val_accuracy: 0.8367
Epoch 90/100
36/36 - 0s - loss: 0.3038 - accuracy: 0.8335 - val_loss: 0.3118 - val_accuracy: 0.8389
Epoch 91/100
36/36 - 0s - loss: 0.3038 - accuracy: 0.8351 - val_loss: 0.3075 - val_accuracy: 0.8546
Epoch 92/100
36/36 - 0s - loss: 0.3075 - accuracy: 0.8335 - val_loss: 0.3239 - val_accuracy: 0.8188
Epoch 93/100
36/36 - 0s - loss: 0.3043 - accuracy: 0.8284 - val_loss: 0.3101 - val_accuracy: 0.8233
Epoch 94/100
36/36 - 0s - loss: 0.3042 - accuracy: 0.8329 - val_loss: 0.3195 - val_accuracy: 0.8054
Epoch 95/100
36/36 - 0s - loss: 0.3069 - accuracy: 0.8279 - val_loss: 0.3202 - val_accuracy: 0.8233
Epoch 96/100
36/36 - 0s - loss: 0.3046 - accuracy: 0.8382 - val_loss: 0.3062 - val_accuracy: 0.8412
Epoch 97/100
36/36 - 0s - loss: 0.3032 - accuracy: 0.8343 - val_loss: 0.3085 - val_accuracy: 0.8345
Epoch 98/100
36/36 - 0s - loss: 0.3005 - accuracy: 0.8357 - val_loss: 0.3155 - val_accuracy: 0.8277
Epoch 99/100
36/36 - 0s - loss: 0.3048 - accuracy: 0.8324 - val_loss: 0.3243 - val_accuracy: 0.8412
Epoch 100/100
36/36 - 0s - loss: 0.3021 - accuracy: 0.8357 - val_loss: 0.3280 - val_accuracy: 0.8166
<tensorflow.python.keras.callbacks.History at 0x1ea0b2e2610>
Note that


000357.png

000358.png

early_stopping = tf.keras.callbacks.EarlyStopping()
000359.png

model.fit(train_inputs,
          
          train_targets, 
          
          batch_size=batch_size, 
          
          epochs=max_epochs,
          
          callbacks=[early_stopping], 
          
          validation_data=(validation_inputs, validation_targets),
          
          verbose = 2 
          )  
Epoch 1/100
36/36 - 0s - loss: 0.3042 - accuracy: 0.8357 - val_loss: 0.3318 - val_accuracy: 0.7987
Epoch 2/100
36/36 - 0s - loss: 0.3030 - accuracy: 0.8338 - val_loss: 0.3113 - val_accuracy: 0.8456
Epoch 3/100
36/36 - 0s - loss: 0.3052 - accuracy: 0.8276 - val_loss: 0.3063 - val_accuracy: 0.8345
Epoch 4/100
36/36 - 0s - loss: 0.3017 - accuracy: 0.8340 - val_loss: 0.3058 - val_accuracy: 0.8367
Epoch 5/100
36/36 - 0s - loss: 0.3004 - accuracy: 0.8357 - val_loss: 0.3078 - val_accuracy: 0.8658
<tensorflow.python.keras.callbacks.History at 0x1ea0ba95730>
let's take the patience into accout
000360.png

000361.png

early_stopping = tf.keras.callbacks.EarlyStopping(patience = 4)


model.fit(train_inputs,
          train_targets, 
          
          batch_size = batch_size, 
          
          epochs = max_epochs,
          
          callbacks = [early_stopping], 
          
          validation_data = (validation_inputs, validation_targets),
          
          verbose = 2 
          )  
Epoch 1/100
36/36 - 0s - loss: 0.3038 - accuracy: 0.8343 - val_loss: 0.3102 - val_accuracy: 0.8277
Epoch 2/100
36/36 - 0s - loss: 0.3041 - accuracy: 0.8360 - val_loss: 0.3194 - val_accuracy: 0.8098
Epoch 3/100
36/36 - 0s - loss: 0.3016 - accuracy: 0.8371 - val_loss: 0.3310 - val_accuracy: 0.8076
Epoch 4/100
36/36 - 0s - loss: 0.3028 - accuracy: 0.8326 - val_loss: 0.3110 - val_accuracy: 0.8277
Epoch 5/100
36/36 - 0s - loss: 0.3046 - accuracy: 0.8343 - val_loss: 0.3156 - val_accuracy: 0.8479
<tensorflow.python.keras.callbacks.History at 0x1ea0bb35c40>
Test the model


000365.png

test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)
14/14 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.7835
print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))
Test loss: 0.37. Test accuracy: 78.35%
000364.png
